{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data to seperate control data\n",
    "control_society_df = pd.read_csv(\"control_society_recommended.csv\")\n",
    "\n",
    "society_data = control_society_df[control_society_df[\"persona\"] == \"Society\"]\n",
    "control_data = control_society_df[control_society_df[\"persona\"] == \"control\"]\n",
    "\n",
    "society_data.to_csv(\"fixed_society_recommended.csv\", index=False)\n",
    "control_data.to_csv(\"fixed_control_society_recommended.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in all datasets is the same.\n"
     ]
    }
   ],
   "source": [
    "# Read each dataset \n",
    "beauty_df = pd.read_csv(\"Beauty_recommended.csv\")\n",
    "sports_df = pd.read_csv(\"sports_recommended.csv\")\n",
    "society_df = pd.read_csv(\"fixed_society_recommended.csv\")\n",
    "control_society_df = pd.read_csv(\"fixed_control_society_recommended.csv\")\n",
    "\n",
    "# Check if the number of rows is the same for all datasets\n",
    "if len(beauty_df) == len(sports_df) == len(society_df) == len(control_society_df):\n",
    "    print(\"Number of rows in all datasets is the same.\")\n",
    "else:\n",
    "    print(\"Number of rows in datasets is not the same. Check your data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count non-empty rec_# columns for each row\n",
    "def count_non_empty(row):\n",
    "    return max(sum(1 for col in row[1:] if isinstance(col, str) and col.startswith(\"https://\")) , 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count non-empty rec_# columns for each row in each dataset\n",
    "beauty_df['beauty_count'] = beauty_df.apply(count_non_empty, axis=1)\n",
    "sports_df['sports_count'] = sports_df.apply(count_non_empty, axis=1)\n",
    "society_df['society_count'] = society_df.apply(count_non_empty, axis=1)\n",
    "control_society_df['control_society_count'] = control_society_df.apply(count_non_empty, axis=1)\n",
    "\n",
    "# Merge the counts into a new DataFrame\n",
    "merged_df = beauty_df[['distributed_link', 'beauty_count']].merge(sports_df[['distributed_link', 'sports_count']], on='distributed_link', how='outer')\n",
    "merged_df = merged_df.merge(society_df[['distributed_link', 'society_count']], on='distributed_link', how='outer')\n",
    "merged_df = merged_df.merge(control_society_df[['distributed_link', 'control_society_count']], on='distributed_link', how='outer')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "# Save the new DataFrame to csv\n",
    "merged_df.to_csv(\"merged_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge for pyktok\n",
    "# Filter the DataFrame to keep only the rows with count of 4 \"8\"s\n",
    "filtered_df = merged_df[(merged_df['beauty_count'] == 8) & \n",
    "                        (merged_df['sports_count'] == 8) & \n",
    "                        (merged_df['society_count'] == 8) & \n",
    "                        (merged_df['control_society_count'] == 8)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/sgypv2yj51sbjjnm2x0y1ryw0000gn/T/ipykernel_26744/4137084009.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['rec_links'] = filtered_df.apply(lambda row: {\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datasets = [(beauty_df, 'beauty'), (sports_df, 'sports'), (society_df, 'society'), (control_society_df, 'control_society')]\n",
    "\n",
    "# Merge all rec_# links from the four datasets\n",
    "filtered_df['rec_links'] = filtered_df.apply(lambda row: {\n",
    "    f\"{prefix}_rec_{i}\": dataset.loc[dataset['distributed_link'] == row['distributed_link'], f\"rec_{i}\"].values[0]\n",
    "    for dataset, prefix in datasets for i in range(1, 9)\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['beauty_count', 'sports_count', 'society_count', 'control_society_count'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Drop unnecessary columns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m filtered_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mbeauty_count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msports_count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msociety_count\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcontrol_society_count\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m json_data \u001b[39m=\u001b[39m filtered_df\u001b[39m.\u001b[39mto_json(orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfiltered_data.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m json_file:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5421\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5422\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5430\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5431\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5432\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5433\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5566\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5567\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdrop(\n\u001b[1;32m   5569\u001b[0m         labels\u001b[39m=\u001b[39mlabels,\n\u001b[1;32m   5570\u001b[0m         axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   5571\u001b[0m         index\u001b[39m=\u001b[39mindex,\n\u001b[1;32m   5572\u001b[0m         columns\u001b[39m=\u001b[39mcolumns,\n\u001b[1;32m   5573\u001b[0m         level\u001b[39m=\u001b[39mlevel,\n\u001b[1;32m   5574\u001b[0m         inplace\u001b[39m=\u001b[39minplace,\n\u001b[1;32m   5575\u001b[0m         errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m   5576\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/generic.py:4785\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4783\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4784\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4785\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_drop_axis(labels, axis, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4787\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4788\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/generic.py:4827\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4825\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4826\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4827\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4828\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4830\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4831\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['beauty_count', 'sports_count', 'society_count', 'control_society_count'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "filtered_df.drop(columns=['beauty_count', 'sports_count', 'society_count', 'control_society_count'], inplace=True)\n",
    "\n",
    "\n",
    "json_data = filtered_df.to_json(orient='records')\n",
    "\n",
    "\n",
    "with open(\"filtered_data.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
