{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b2453d",
   "metadata": {},
   "source": [
    "# Using Naive Bayes to classify recommended TikTok videos\n",
    "\n",
    "Classify videos as either Beauty, Sports, Society, or Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be588dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b7ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b082d7",
   "metadata": {},
   "source": [
    "For videos with a Pyktok-provided diversification label, assign video a corresponding category (sports, beauty, society, other):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79953708",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyk_df = pd.read_csv('pyktok_output.csv')\n",
    "def determine_category(info): #method written by Johanna\n",
    "    if type(info) == str:\n",
    "        if 'sports' in info.lower() or 'fitness' in info.lower() or 'outdoor' in info.lower():\n",
    "            return 'sports'\n",
    "        elif 'beauty' in info.lower() or 'style' in info.lower():\n",
    "            return 'beauty'\n",
    "        elif 'society' in info.lower() or 'news' in info.lower() or 'social issues' in info.lower():\n",
    "            return 'society'\n",
    "        else:\n",
    "            return 'other'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#label category    \n",
    "pyk_df['category'] = pyk_df['diversificationLabels'].apply(determine_category)\n",
    "pyk_df['video_id'] = pyk_df['video_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8385ec2",
   "metadata": {},
   "source": [
    "Clean and prepare the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d801bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/lld31hms2tzffwdqgcdg20jc0000gn/T/ipykernel_60618/2484355691.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  pyk_df['description'] = pyk_df.description.str.replace('[^\\w\\s]', '')\n"
     ]
    }
   ],
   "source": [
    "#remove rows that have neither suggested_words nor video_description\n",
    "pyk_df.dropna(subset=['suggested_words', 'video_description'], how='all', inplace=True)\n",
    "\n",
    "#merge the suggested_words and video_description columns\n",
    "pyk_df['description'] = pyk_df['suggested_words'].combine_first(pyk_df['video_description'])\n",
    "\n",
    "#lowercase and remove punctuation\n",
    "pyk_df['description'] = pyk_df.description.map(lambda x: x.lower())\n",
    "pyk_df['description'] = pyk_df.description.str.replace('[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1070a",
   "metadata": {},
   "source": [
    "Let's see how many videos of each category we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "996ee072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other      1135\n",
       "beauty      398\n",
       "sports      196\n",
       "society     193\n",
       "None        126\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = pyk_df['category'].value_counts(dropna=False)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b683838",
   "metadata": {},
   "source": [
    "As we can see above, the Pyktok data has an unequal number of videos corresponding to each category. For training our classifier, we want a balanced dataset. So let's keep about 200 random videos for each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fb2678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows corresponding to the 'beauty', 'other' categores\n",
    "beauty_df = pyk_df[pyk_df['category'] == 'beauty']\n",
    "other_df = pyk_df[pyk_df['category'] == 'other']\n",
    "\n",
    "beauty_df = beauty_df.sample(n=200, random_state=1)  \n",
    "other_df = other_df.sample(n=200, random_state=1)\n",
    "\n",
    "# Filter rows corresponding to the sports or no categories\n",
    "remaining_df = pyk_df[(pyk_df['category'] != 'beauty') & (pyk_df['category'] != 'other')]\n",
    "\n",
    "# Concatenate the new dataframes of 200 videos each\n",
    "balanced_df = pd.concat([beauty_df, other_df, remaining_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032238d6",
   "metadata": {},
   "source": [
    "Next we'll tokenize the descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b07a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46d2f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df['description'] = balanced_df['description'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701ddd34",
   "metadata": {},
   "source": [
    "For training our classifier, we only want the labeled data (videos with Pyktok diversification labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511a3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = balanced_df[balanced_df['category'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b2d3a",
   "metadata": {},
   "source": [
    "Use CountVectorizer to transform data into occurrences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6646abc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/lld31hms2tzffwdqgcdg20jc0000gn/T/ipykernel_60618/1829658176.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labeled_df['description'] = labeled_df['description'].apply(lambda x: ' '.join(x))\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# This converts the list of words into space-separated strings\n",
    "labeled_df['description'] = labeled_df['description'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "counts = count_vectorizer.fit_transform(labeled_df['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348301d",
   "metadata": {},
   "source": [
    "Use TF-IDF as model features instead of word counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34131bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(counts)\n",
    "\n",
    "counts = tfidf_transformer.transform(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84a9cf",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04c7227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, labeled_df['category'], \n",
    "                                                    test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7c06b",
   "metadata": {},
   "source": [
    "Now we can fit the data to a Naive Bayes classifier. We use the Multinomial Naive Bayes Classifier here for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f389438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c4a83",
   "metadata": {},
   "source": [
    "We'll use cross validation to check the accuracy of the model on different subsections of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baa1ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies=cross_val_score(estimator=model,X=X_train,y=y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cc76711",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.609375   0.76190476 0.76190476 0.79365079 0.77777778 0.71428571\n",
      " 0.63492063 0.63492063 0.66666667 0.6984127 ]\n",
      "Average accuracy: 0.7053819444444445\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)\n",
    "print(\"Average accuracy:\", sum(accuracies)/len(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb4f40",
   "metadata": {},
   "source": [
    "These accuracies aren't spectacular, but they're not bad. It seems like our classifier can be used as a fairly good estimator for the category of each video. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbb493",
   "metadata": {},
   "source": [
    "### So, let's use our newly trained Naive Bayes classifier to categorize unlabeled videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5413df7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 23)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows with NaN 'category' values\n",
    "unlabeled_df = pyk_df[pyk_df['category'].isna()]\n",
    "unlabeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "543a5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the unlabeled data into counts and then TF-IDF features:\n",
    "X_unlabeled_counts = count_vectorizer.transform(unlabeled_df['description']) \n",
    "X_unlabeled_tfidf = tfidf_transformer.transform(X_unlabeled_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61b259ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/lld31hms2tzffwdqgcdg20jc0000gn/T/ipykernel_60618/1037925780.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabeled_df['category'] = predicted_categories\n"
     ]
    }
   ],
   "source": [
    "#Predict categories and add to our Pyktok data\n",
    "predicted_categories = model.predict(X_unlabeled_tfidf)\n",
    "\n",
    "unlabeled_df['category'] = predicted_categories\n",
    "\n",
    "pyk_df.update(unlabeled_df)\n",
    "updated_pyk_df = pyk_df.dropna(subset=['category'])\n",
    "updated_pyk_df.to_csv('categorized_pyktok.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
